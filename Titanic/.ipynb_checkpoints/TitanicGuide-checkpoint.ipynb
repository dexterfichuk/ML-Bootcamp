{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionary\n",
    "\n",
    "## Variable:\tDefinition\tKey\n",
    "survival:\tSurvival\t0 = No, 1 = Yes\n",
    "\n",
    "pclass:\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "\n",
    "sex:\tSex\t\n",
    "\n",
    "Age:\tAge in years\t\n",
    "\n",
    "sibsp:\t# of siblings / spouses aboard the Titanic\t\n",
    "\n",
    "parch:\t# of parents / children aboard the Titanic\t\n",
    "\n",
    "ticket:\tTicket number\t\n",
    "\n",
    "fare:\tPassenger fare\t\n",
    "\n",
    "cabin:\tCabin number\t\n",
    "\n",
    "embarked:\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "## Variable Notes\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelimenary Stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import some libraries we'll use, and set matplotlib to be inline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now load in the data into a 'dataframe'\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Jupyter, we can simply print a dataframe just by putting it as the last block of code in a cell\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From quickly browsing our dataset, we can see that there are a lot of NaN (null) values for the Cabin and that the values for ticket are pretty inconsistent, so we can drop them very easily with pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bash Commands!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specific features from our dataframe\n",
    "df = df.drop(['Ticket','Cabin', 'PassengerId'], axis=1)\n",
    "\n",
    "# Remove NaN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now lets transform the sex field to be a binary gender field called male\n",
    "df['Male'] = np.where(df['Sex']=='male', 1, 0) \n",
    "\n",
    "# Now lets drop the sex field altogether\n",
    "# We can drop the name, since it is irrelevant\n",
    "df = df.drop(['Sex', 'Name'], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's turn the Embarked column into one hot encoding\n",
    "df = pd.concat([df, pd.get_dummies(df['Embarked'])], axis=1)\n",
    "\n",
    "# Now drop the original embarked\n",
    "df = df.drop(['Embarked'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.hist(figsize=(25,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks for survived/not survived passengers by their age\n",
    "facet = sns.FacetGrid(df, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, df['Age'].max()))\n",
    "facet.add_legend()\n",
    "\n",
    "# average survived passengers by age\n",
    "fig, axis1 = plt.subplots(1,1,figsize=(20,4))\n",
    "average_age = df[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\n",
    "sns.barplot(x='Age', y='Survived', data=average_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to split the data. Lucky for us, sklearn has a great built-in split function. We need to make sure to set the random state so the split of data is the same everytime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Our y will be the survived column so we'll add it then drop it from our X set\n",
    "y = df['Survived']\n",
    "X = df.drop(['Survived'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "The first algorithm we'll tryout is called Linear Regression. It serves as great baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll tryout the basic LR algorithm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_clf = LinearRegression()\n",
    "\n",
    "# First we'll train the model on our data.\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "preds = lr_clf.predict(X_test)\n",
    "\n",
    "# LR predicts confidences, so we have to round it\n",
    "preds = np.rint(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "A powerful, simple approach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' , n_estimators=40, oob_score = True, random_state=42) \n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "preds = rfc.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also view the weighted importances of the columns based on a classifier\n",
    "importances = rfc.feature_importances_\n",
    "\n",
    "for i in range(len(X_train.columns)):\n",
    "    print(X_train.columns[i], '\\t', importances[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see that the 3 most important features are the passengers gender, fare, and age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "Now, instead of just using th default parameters, we'll setup a gridsearch of multiple combinations to train on, then view the top ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' , n_estimators=40, oob_score = True, random_state=42) \n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 25, 30, 40],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv = 5)\n",
    "\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(CV_rfc.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS! Would you survive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "survival: Survival 0 = No, 1 = Yes\n",
    "\n",
    "pclass: Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "\n",
    "sex: Sex\n",
    "\n",
    "Age: Age in years\n",
    "\n",
    "sibsp: # of siblings / spouses aboard the Titanic\n",
    "\n",
    "parch: # of parents / children aboard the Titanic\n",
    "\n",
    "ticket: Ticket number\n",
    "\n",
    "fare: Passenger fare\n",
    "\n",
    "cabin: Cabin number\n",
    "\n",
    "embarked: Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "you = {\n",
    "    'Pclass': 1, # class of passenger\n",
    "    'Age': 23,  # your age\n",
    "    'SibSp': 1, # num siblings aboard\n",
    "    'Parch': 2, # num parents aboard\n",
    "    'Fare': 10, # how much you paid\n",
    "    'Male': 1, # true if male\n",
    "    'C': 0, # city embarked from, one of these should be 1 and the others 0\n",
    "    'Q': 1,\n",
    "    'S': 0\n",
    "}\n",
    "you = list(you.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking our trained random forest and predicting if you gonna make it\n",
    "if rfc.predict([you])[0] == 0:\n",
    "    print(\"Sorry, you wouldn't make it :'''''')\")\n",
    "else:\n",
    "    print(\"You're gonna make it!! :')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
